{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Current Time:     2019/10/19  13:56:48\n",
      "[info] Python Version:   3.6.8\n",
      "[info] Working Dir:      /host/home/python/musegan_npz/github_repository/ver2/\n",
      "[info] Tensorflow:       1.8.0\n",
      "[info] GPU device:       GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import librosa, IPython, pickle, datetime, time, os, sys, copy, glob\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_ops import *\n",
    "from tf_util import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# show version info\n",
    "print (\"[info] Current Time:     \" + datetime.datetime.now().strftime('%Y/%m/%d  %H:%M:%S'))\n",
    "print (\"[info] Python Version:   \" + sys.version.split('\\n')[0].split(' ')[0])\n",
    "print (\"[info] Working Dir:      \" + os.getcwd()+'/')\n",
    "print (\"[info] Tensorflow:       \" + tf.__version__)\n",
    "\n",
    "# enable gpu usage constraint here\n",
    "limited_gpu_usage = 1; occupied_gpu_dev = 0;\n",
    "\n",
    "# if gpu usage is constraint, limit certain gpu for use\n",
    "if (limited_gpu_usage == 1):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"                       # list GPU sequence by PCI bus GPU ID                   \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(occupied_gpu_dev)   \n",
    "\n",
    "    # check available GPU\n",
    "    from tensorflow.python.client import device_lib\n",
    "    for x in range(1, len(device_lib.list_local_devices())):\n",
    "        print (\"[info] GPU device:       \" + device_lib.list_local_devices()[x].physical_device_desc[17:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload song/bar index code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] List of [song/bar] data is loaded.\n",
      "[info] Total bars: 2311\n",
      "[info] First 5 bar code: ['00000_000', '00000_001', '00000_002', '00000_003', '00000_004']\n",
      "[info] Last  5 bar code: ['00023_141', '00023_142', '00023_143', '00023_144', '00023_145']\n"
     ]
    }
   ],
   "source": [
    "with open('./pre_processed_data/abs_bar_idx_str_list.pkl', 'rb') as pkl_file:        \n",
    "    abs_bar_idx_str_list = pickle.load(pkl_file)\n",
    "    \n",
    "print ('[info] List of [song/bar] data is loaded.')\n",
    "print ('[info] Total bars: {}'.format(len(abs_bar_idx_str_list)))\n",
    "print ('[info] First 5 bar code: {}'.format(abs_bar_idx_str_list[:5]))\n",
    "print ('[info] Last  5 bar code: {}'.format(abs_bar_idx_str_list[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define basic CQT read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Total # of CQT files: 24\n",
      "[info] CQT reading function defined.\n"
     ]
    }
   ],
   "source": [
    "read_pooled_cqt_flist = np.sort(glob.glob('./pre_processed_data/cqt_pooled_data/*.pkl', recursive=True)).tolist()\n",
    "print ('[info] Total # of CQT files: {}'.format(len(read_pooled_cqt_flist)))\n",
    "\n",
    "def get_bar_cqt_data(abd_bar_idx_str):\n",
    "    \n",
    "    song_idx = int(abd_bar_idx_str.split('_')[0])\n",
    "    bar_idx = int(abd_bar_idx_str.split('_')[1])\n",
    "    \n",
    "    file_name = read_pooled_cqt_flist[song_idx]\n",
    "    with open(file_name, 'rb') as pkl_file:\n",
    "        pooled_cqt_data = pickle.load(pkl_file)  \n",
    "        \n",
    "    bar_cqt_data = pooled_cqt_data[bar_idx]\n",
    "    \n",
    "    return(bar_cqt_data)\n",
    "    \n",
    "print ('[info] CQT reading function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define function to load drum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Total # of drum tracks: 24\n",
      "[info] Single-bar drum data shape: (46, 16)\n"
     ]
    }
   ],
   "source": [
    "file_name = './pre_processed_data/cdsed_drum_bar_list_28_46/song_drum_bar_list_46.pkl'   \n",
    "with open(file_name, 'rb') as pkl_file:\n",
    "    song_drum_bar_list_46 = pickle.load(pkl_file)\n",
    "\n",
    "song_idx = 10; bar_idx = 30;\n",
    "print('[info] Total # of drum tracks: {}'.format(len(song_drum_bar_list_46)))\n",
    "print('[info] Single-bar drum data shape: {}'.format(song_drum_bar_list_46[song_idx][bar_idx].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set note complexity parameter list [ +0 / +3 / +6 / +12 / +20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_add_note_num_list = [0, 3, 6, 12, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define funtion to get data by index code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] data pkg out[0] shape: (84, 96, 8)\n",
      "[info] data pkg out[1] shape: (8,)\n",
      "[info] data pkg out[2] shape: (10,)\n",
      "[info] data pkg out[3] shape: (16,)\n",
      "[info] data pkg out[4] shape: (10,)\n",
      "[info] data pkg out[5] shape: (1,)\n",
      "[info] data pkg out[6] shape: (46, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# read bar selection data\n",
    "with open('./pre_processed_data/vaegan_bar_selection_index_list.pkl', 'rb') as pkl_file:\n",
    "    bar_selection_list = pickle.load(pkl_file)\n",
    "\n",
    "# read song attribute\n",
    "with open('./pre_processed_data/all_song_attribute.pkl', 'rb') as pkl_file:\n",
    "    song_attribute_data_list = pickle.load(pkl_file)    \n",
    "\n",
    "\n",
    "# define python read function\n",
    "def read_pkl_function(index_code_in):\n",
    "    \n",
    "    # convert data into correct type\n",
    "    if type(index_code_in)!=str:\n",
    "        index_code_in = index_code_in.decode(\"utf-8\")\n",
    "        \n",
    "    # extract information from index code\n",
    "    song_idx_str = index_code_in.split('_')[0]\n",
    "    song_idx_int = int(song_idx_str)\n",
    "    bar_idx_str = index_code_in.split('_')[1]\n",
    "    bar_idx_int = int(bar_idx_str)\n",
    "    \n",
    "    # set parameter to get relative bars\n",
    "    get_n_rtv_bars = 7\n",
    "    rtv_bar_index = np.round(bar_selection_list[int(song_idx_str)][int(bar_idx_str), 0, 0:get_n_rtv_bars]).astype(int)\n",
    "    rtv_bar_ratio = np.hstack([1.0, bar_selection_list[int(song_idx_str)][int(bar_idx_str), 1, 0:get_n_rtv_bars]]).astype(np.float32)\n",
    "    \n",
    "    # collect 8-bars CQT data\n",
    "    cqt_data_rtv_bar_list = []\n",
    "    \n",
    "    for cqt_bar_idx in range(0, 8):\n",
    "        \n",
    "        # get current bar data\n",
    "        if cqt_bar_idx==0:\n",
    "            cqt_data_rtv_bar_list.append(get_bar_cqt_data(index_code_in))\n",
    "            \n",
    "        # get 7-relative bars data\n",
    "        else:\n",
    "            index_code_tmp = song_idx_str + '_' + '{:0>3}'.format(rtv_bar_index[cqt_bar_idx-1])\n",
    "            cqt_data_rtv_bar_list.append(get_bar_cqt_data(index_code_tmp))\n",
    "    \n",
    "    # process CQT data\n",
    "    cqt_data_fname_rtv_mix = np.concatenate([cqt_data_rtv_bar_list[0][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[1][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[2][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[3][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[4][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[5][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[6][:,:,np.newaxis],\n",
    "                                             cqt_data_rtv_bar_list[7][:,:,np.newaxis]], axis=-1).astype(np.float32)\n",
    "            \n",
    "    # reload original MIDI drum data for reference\n",
    "    drum_bar_data_reload = song_drum_bar_list_46[song_idx_int][bar_idx_int][:,:,np.newaxis].astype(np.float32)\n",
    "    \n",
    "\n",
    "    # process song attributes    \n",
    "    attribute_data_list = song_attribute_data_list[song_idx_int]\n",
    "    tempo_norm_v_oh =     attribute_data_list[1].astype(np.float32)\n",
    "    style_tag_array_oh =  attribute_data_list[2].astype(np.float32)\n",
    "    song_progress_oh =    attribute_data_list[3][int(bar_idx_str),:].astype(np.float32)\n",
    "    n_note_in_bar =       np.array([attribute_data_list[4][int(bar_idx_str)]]).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    # send back data\n",
    "    return (cqt_data_fname_rtv_mix,  \\\n",
    "            rtv_bar_ratio,           \\\n",
    "            tempo_norm_v_oh,         \\\n",
    "            style_tag_array_oh,      \\\n",
    "            song_progress_oh,        \\\n",
    "            n_note_in_bar,           \\\n",
    "            drum_bar_data_reload)\n",
    "    \n",
    "    \n",
    "# check data format\n",
    "py_func_out_cqt_data,     \\\n",
    "py_func_out_cqt_ratio,    \\\n",
    "py_func_out_tempo_att,    \\\n",
    "py_func_out_style_att,    \\\n",
    "py_func_out_progress_att, \\\n",
    "py_func_out_n_note_att,   \\\n",
    "py_func_out_drum_arrange = read_pkl_function(abs_bar_idx_str_list[0])\n",
    "\n",
    "# show data format\n",
    "print ('[info] data pkg out[0] shape: {}'.format(py_func_out_cqt_data.shape))\n",
    "print ('[info] data pkg out[1] shape: {}'.format(py_func_out_cqt_ratio.shape))\n",
    "print ('[info] data pkg out[2] shape: {}'.format(py_func_out_tempo_att.shape))\n",
    "print ('[info] data pkg out[3] shape: {}'.format(py_func_out_style_att.shape))\n",
    "print ('[info] data pkg out[4] shape: {}'.format(py_func_out_progress_att.shape))\n",
    "print ('[info] data pkg out[5] shape: {}'.format(py_func_out_n_note_att.shape))\n",
    "print ('[info] data pkg out[6] shape: {}'.format(py_func_out_drum_arrange.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset.map function data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] \"dataset.map\" function is defined.\n"
     ]
    }
   ],
   "source": [
    "trf_out0_shape = py_func_out_cqt_data.shape\n",
    "trf_out1_shape = py_func_out_cqt_ratio.shape\n",
    "trf_out2_shape = py_func_out_tempo_att.shape\n",
    "trf_out3_shape = py_func_out_style_att.shape\n",
    "trf_out4_shape = py_func_out_progress_att.shape\n",
    "trf_out5_shape = py_func_out_n_note_att.shape\n",
    "trf_out6_shape = py_func_out_drum_arrange.shape\n",
    "\n",
    "def tf_reshape_function(trf_out0, trf_out1, trf_out2, trf_out3, trf_out4, trf_out5, trf_out6):\n",
    "    \n",
    "    trf_out0.set_shape(trf_out0_shape)    # cqt data\n",
    "    trf_out1.set_shape(trf_out1_shape)    # cqt data ratio\n",
    "    trf_out2.set_shape(trf_out2_shape)    # tempo data\n",
    "    trf_out3.set_shape(trf_out3_shape)    # style data\n",
    "    trf_out4.set_shape(trf_out4_shape)    # song progress\n",
    "    trf_out5.set_shape(trf_out5_shape)    # note number in bar\n",
    "    trf_out6.set_shape(trf_out6_shape)    # drum arrange    \n",
    "    \n",
    "    return trf_out0, trf_out1, trf_out2, trf_out3, trf_out4, trf_out5, trf_out6\n",
    "\n",
    "print('[info] \\\"dataset.map\\\" function is defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define TF dataset API for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Original list len: 2311, batch num: 36.109375\n",
      "[info] Extended list len: 2368, batch num: 37\n",
      "[info] Total test index codes: 2368\n",
      "[info] TF test Data API is defined.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# extend list to match needed batch size\n",
    "abs_bar_idx_str_list_ext = copy.deepcopy(abs_bar_idx_str_list)\n",
    "abs_bar_idx_str_list_ext.extend(copy.deepcopy(abs_bar_idx_str_list))\n",
    "\n",
    "extend_list_len = ((len(abs_bar_idx_str_list)//batch_size) + \\\n",
    "                    np.int(np.ceil((len(abs_bar_idx_str_list)%batch_size)/batch_size))) * batch_size\n",
    "\n",
    "abs_bar_idx_str_list_ext = abs_bar_idx_str_list_ext[:extend_list_len]\n",
    "\n",
    "orig_list_n = len(abs_bar_idx_str_list); extd_list_n = len(abs_bar_idx_str_list_ext); \n",
    "print ('[info] Original list len: {}, batch num: {}'.format(orig_list_n, orig_list_n/batch_size))\n",
    "print ('[info] Extended list len: {}, batch num: {}'.format(extd_list_n, int(extd_list_n/batch_size)))\n",
    "\n",
    "print ('[info] Total test index codes: {}'.format(len(abs_bar_idx_str_list_ext)))\n",
    "\n",
    "darr_test_dataset = tf.data.Dataset.from_tensor_slices((abs_bar_idx_str_list_ext))\n",
    "darr_test_dataset = darr_test_dataset.map(lambda index_code_test: tuple(tf.py_func(read_pkl_function,                    \n",
    "                                                                                   [index_code_test],\n",
    "                                                                                   [tf.float32, \n",
    "                                                                                    tf.float32, \n",
    "                                                                                    tf.float32, \n",
    "                                                                                    tf.float32, \n",
    "                                                                                    tf.float32, \n",
    "                                                                                    tf.float32, \n",
    "                                                                                    tf.float32])),\n",
    "                                           num_parallel_calls=8)\n",
    "\n",
    "darr_test_dataset = darr_test_dataset.map(tf_reshape_function, num_parallel_calls=8)\n",
    "darr_test_dataset = darr_test_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "test_iter = darr_test_dataset.make_initializable_iterator()\n",
    "\n",
    "# get batch data\n",
    "batch_bar_cqt_data_test,         \\\n",
    "batch_bar_cqt_ratio_test,        \\\n",
    "batch_bar_tempo_data_test,       \\\n",
    "batch_bar_style_data_test,       \\\n",
    "batch_bar_progress_test,         \\\n",
    "batch_bar_note_num_test,         \\\n",
    "batch_bar_arrange_test = test_iter.get_next()\n",
    "\n",
    "# define TF-placeholder to hold note complexity adjust value\n",
    "tfph_bar_add_note_num = tf.placeholder(tf.float32, shape=(1))\n",
    "\n",
    "print('[info] TF test Data API is defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Encoder define done.\n"
     ]
    }
   ],
   "source": [
    "# define leaky relu function\n",
    "def lrelu(x, alpha=0.05):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))\n",
    "\n",
    "n_latent = 32\n",
    "\n",
    "# define spectrogram encoder\n",
    "def spec_encoder(enc_song_tempo,        # (batch_num, 10)\n",
    "                 enc_style_id,          # (batch_num, 15)\n",
    "                 enc_song_progress,     # (batch_num, 10)  \n",
    "                 enc_spectrogram,       # (batch_num, 84, 96, 2)\n",
    "                 reuse=False):\n",
    "    \n",
    "    with tf.variable_scope('spec_nn_enc', reuse=reuse):\n",
    "        \n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse is False    \n",
    "        \n",
    "        # define song_tempo input layer\n",
    "        enc_song_tempo_i_layer = tf.layers.dense(inputs=enc_song_tempo,\n",
    "                                                 units=64,\n",
    "                                                 activation=lrelu,\n",
    "                                                 name='enc_nn_at1')                                                    \n",
    "\n",
    "        # define style_id input layer\n",
    "        enc_style_id_i_layer = tf.layers.dense(inputs=enc_style_id,\n",
    "                                               units=64,\n",
    "                                               activation=lrelu,\n",
    "                                               name='enc_nn_at2')          \n",
    "        # define song_progress input layer\n",
    "        enc_song_progress_i_layer = tf.layers.dense(inputs=enc_song_progress,\n",
    "                                                    units=64,\n",
    "                                                    activation=lrelu,\n",
    "                                                    name='enc_nn_at3')\n",
    "        \n",
    "        # make padding Batch / Height / Width / Channel \n",
    "        enc_spectrogram_pad = tf.pad(enc_spectrogram, [[0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\n",
    "                \n",
    "        enc_conv_h1 = tf.nn.elu(instance_norm(conv2d(enc_spectrogram_pad, \n",
    "                                                     output_dim=48,\n",
    "                                                     ks=[4,4],\n",
    "                                                     s=[1,1], \n",
    "                                                     name='enc_conv1'), 'enc_bn1'))\n",
    "    \n",
    "        enc_conv_h2 = tf.nn.elu(instance_norm(conv2d(enc_conv_h1, \n",
    "                                                     output_dim=48,\n",
    "                                                     ks=[4,4],\n",
    "                                                     s=[2,2], \n",
    "                                                     name='enc_conv2'), 'enc_bn2'))\n",
    "        \n",
    "        enc_conv_h3 = tf.nn.elu(instance_norm(conv2d(enc_conv_h2,\n",
    "                                                     output_dim=72,\n",
    "                                                     ks=[4,4],\n",
    "                                                     s=[2,2], \n",
    "                                                     name='enc_conv3'), 'enc_bn3'))\n",
    "    \n",
    "    \n",
    "        # flatten conv output\n",
    "        enc_convo_flat_out = tf.reshape(enc_conv_h3, [-1, np.prod(enc_conv_h3.get_shape()[1:])])\n",
    "        \n",
    "        # concat all decoder input layers\n",
    "        enc_merged_layer = tf.concat([enc_song_tempo_i_layer,       \\\n",
    "                                      enc_style_id_i_layer,         \\\n",
    "                                      enc_song_progress_i_layer,    \\\n",
    "                                      enc_convo_flat_out],          \\\n",
    "                                     axis=1,                        \\\n",
    "                                     name='enc_nn_in_concat')\n",
    "    \n",
    "        \n",
    "        enc_mlp_h1 = tf.layers.dense(inputs=enc_merged_layer,\n",
    "                                 units=1024,\n",
    "                                 activation=lrelu,\n",
    "                                 name='enc_nn_mid_h1')\n",
    "        \n",
    "        enc_mlp_h2 = tf.layers.dense(inputs=enc_mlp_h1,\n",
    "                                 units=1024,\n",
    "                                 activation=lrelu,\n",
    "                                 name='enc_nn_mid_h2')\n",
    "\n",
    "        enc_mlp_h2m = lrelu(enc_mlp_h2 + enc_mlp_h1*0.2)\n",
    "        \n",
    "        enc_mlp_h3 = tf.layers.dense(inputs=enc_mlp_h2m,\n",
    "                                     units=1024,\n",
    "                                     activation=lrelu,\n",
    "                                     name='enc_nn_mid_h3')\n",
    "        \n",
    "        enc_mlp_h3m = lrelu(enc_mlp_h3 + enc_mlp_h2m*0.2)      \n",
    "        \n",
    "        \n",
    "        # define encoder output layer\n",
    "        z_mean = tf.layers.dense(inputs=enc_mlp_h3m,\n",
    "                                 units=n_latent,\n",
    "                                 activation=None,\n",
    "                                 name='enco_mean')\n",
    "            \n",
    "        z_std = tf.layers.dense(inputs=enc_mlp_h3m, \n",
    "                                units=n_latent, \n",
    "                                activation=None,\n",
    "                                name='enco_std')\n",
    "        \n",
    "        z_epsilon = tf.random_normal(tf.stack([tf.shape(enc_mlp_h3m)[0], n_latent])) \n",
    "        \n",
    "        z_latent  = z_mean + tf.multiply(z_epsilon, tf.exp(z_std * 0.5))\n",
    "        \n",
    "        enc_n_note_h1 = tf.layers.dense(inputs=enc_mlp_h3m, \n",
    "                                        units=512, \n",
    "                                        activation=lrelu,\n",
    "                                        name='enc_nnp_h1')\n",
    "\n",
    "        enc_n_note_h2 = tf.layers.dense(inputs=enc_n_note_h1, \n",
    "                                        units=512, \n",
    "                                        activation=lrelu,\n",
    "                                        name='enc_nnp_h2')        \n",
    "        \n",
    "        enc_n_note_pridiction = tf.layers.dense(inputs=enc_n_note_h2, \n",
    "                                                units=1, \n",
    "                                                activation=tf.nn.sigmoid,\n",
    "                                                name='enco_nnp_out')\n",
    "        \n",
    "        enc_n_note_pridiction_x256 = (enc_n_note_pridiction * 256) - 10\n",
    "        \n",
    "        return z_latent, z_mean, z_std, enc_n_note_pridiction_x256\n",
    "    \n",
    "print ('[info] Encoder define done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Decoder define done.\n"
     ]
    }
   ],
   "source": [
    "dec_output_size = np.prod(trf_out6_shape)   # bar_arrange, out[5] shape: (46, 16, 1)\n",
    "dec_output_size_4d = [-1, trf_out6_shape[0], trf_out6_shape[1], 1]\n",
    "\n",
    "# define leaky relu function\n",
    "def lrelu(x, alpha=0.05):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))\n",
    "\n",
    "# define spectrogram encoder\n",
    "def spec_decoder(dec_song_tempo,        # (batch_num, 10)\n",
    "                 dec_style_id,          # (batch_num, 15)\n",
    "                 dec_song_progress,     # (batch_num, 10)   \n",
    "                 dec_bar_note_num,      # (batch_num, 1)\n",
    "                 dec_z_sampled,         # (batch_num, 32)                 \n",
    "                 reuse=False):\n",
    "    \n",
    "    with tf.variable_scope('spec_nn_dec', reuse=reuse):\n",
    "        \n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            \n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse is False          \n",
    "            \n",
    "        # define song_tempo input layer\n",
    "        dec_song_tempo_i_layer = tf.layers.dense(inputs=dec_song_tempo,\n",
    "                                                 units=64,\n",
    "                                                 activation=lrelu,\n",
    "                                                 name='dec_nn_at1')                                                    \n",
    "\n",
    "        # define style_id input layer\n",
    "        dec_style_id_i_layer = tf.layers.dense(inputs=dec_style_id,\n",
    "                                               units=64,\n",
    "                                               activation=lrelu,\n",
    "                                               name='dec_nn_at2')          \n",
    "        # define song_progress input layer\n",
    "        dec_song_progress_i_layer = tf.layers.dense(inputs=dec_song_progress,\n",
    "                                                    units=64,\n",
    "                                                    activation=lrelu,\n",
    "                                                    name='dec_nn_at3')\n",
    "        \n",
    "        # define bar_note_num input layer\n",
    "        dec_bar_note_num_limited = tf.clip_by_value(dec_bar_note_num,\n",
    "                                                    0.0,\n",
    "                                                    200.0)\n",
    "        \n",
    "        dec_bar_note_num_i_layer = tf.layers.dense(inputs=dec_bar_note_num_limited,\n",
    "                                                   units=64,\n",
    "                                                   activation=lrelu,\n",
    "                                                   name='dec_nn_at4')\n",
    "        \n",
    "        # define z input layer\n",
    "        dec_z_i_layer = tf.layers.dense(inputs=dec_z_sampled,\n",
    "                                        units=256,\n",
    "                                        activation=lrelu,\n",
    "                                        name='dec_nn_at5')\n",
    "        \n",
    "        # concat all decoder input layers\n",
    "        dec_merged_layer = tf.concat([dec_song_tempo_i_layer,       \\\n",
    "                                      dec_style_id_i_layer,         \\\n",
    "                                      dec_song_progress_i_layer,    \\\n",
    "                                      dec_bar_note_num_i_layer,     \\\n",
    "                                      dec_z_i_layer],               \\\n",
    "                                     axis=1,                        \\\n",
    "                                     name='dec_nn_in_concat')\n",
    "                \n",
    "        dec_mlp_h1 = tf.layers.dense(inputs=dec_merged_layer,\n",
    "                                     units=1024,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h1')                                     \n",
    "        \n",
    "        dec_mlp_h2 = tf.layers.dense(inputs=dec_mlp_h1,\n",
    "                                     units=1024,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h2')   \n",
    "        \n",
    "        dec_mlp_h2m = lrelu(dec_mlp_h2 + dec_mlp_h1*0.2)\n",
    "        \n",
    "        dec_mlp_h3 = tf.layers.dense(inputs=dec_mlp_h2m,\n",
    "                                     units=2048,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h3')\n",
    "        \n",
    "        dec_mlp_h4 = tf.layers.dense(inputs=dec_mlp_h3,\n",
    "                                     units=2048,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h4')\n",
    "        \n",
    "        dec_mlp_h4m = lrelu(dec_mlp_h4 + dec_mlp_h3*0.2)\n",
    "        \n",
    "        dec_mlp_h5 = tf.layers.dense(inputs=dec_mlp_h4m,\n",
    "                                     units=2048,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h5')\n",
    "        \n",
    "        dec_mlp_h5m = lrelu(dec_mlp_h5 + dec_mlp_h4m*0.2)\n",
    "        \n",
    "        dec_mlp_h6 = tf.layers.dense(inputs=dec_mlp_h5m,\n",
    "                                     units=2048,\n",
    "                                     activation=lrelu,\n",
    "                                     name='dec_nn_mid_h6')\n",
    "        \n",
    "        dec_mlp_h6m = lrelu(dec_mlp_h6 + dec_mlp_h5m*0.2)\n",
    "        \n",
    "        # final output layer use tanh\n",
    "        dec_mlp_output = tf.layers.dense(inputs=dec_mlp_h6m,\n",
    "                                         units=dec_output_size,                        \n",
    "                                         activation=tf.nn.tanh,\n",
    "                                         name='dec_nn_out_final')        \n",
    "        \n",
    "        # normalize output range to -1.5 ~ 2.5\n",
    "        #dec_mlp_output_norm = (dec_mlp_output * 4.0) + 0.5        \n",
    "        dec_mlp_output_norm = lrelu((dec_mlp_output * 2.0) + 0.5)\n",
    "        \n",
    "        # reshape data into 4d shape\n",
    "        dec_output_reshape = tf.reshape(dec_mlp_output_norm, dec_output_size_4d)\n",
    "        \n",
    "        return dec_output_reshape\n",
    "\n",
    "print ('[info] Decoder define done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Model Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] VAE test model is connected.\n"
     ]
    }
   ],
   "source": [
    "# connect model for testing data\n",
    "processed_cqt_data_test = apply_cqt_ratio(batch_bar_cqt_data_test, batch_bar_cqt_ratio_test)\n",
    "processed_cqt_data_double_layer_test = get_matx_2_layer_tf(processed_cqt_data_test)\n",
    "\n",
    "vae_latent_z_test,     \\\n",
    "vae_latent_zmn_test,   \\\n",
    "vae_latent_zsd_test,   \\\n",
    "vae_note_pred_test = spec_encoder(batch_bar_tempo_data_test,                   \\\n",
    "                                  batch_bar_style_data_test,                   \\\n",
    "                                  batch_bar_progress_test,                     \\\n",
    "                                  processed_cqt_data_double_layer_test,        \\\n",
    "                                  reuse=False)\n",
    "\n",
    "vae_drum_out_test = spec_decoder(batch_bar_tempo_data_test,                    \\\n",
    "                                 batch_bar_style_data_test,                    \\\n",
    "                                 batch_bar_progress_test,                      \\\n",
    "                                 vae_note_pred_test + tfph_bar_add_note_num,   \\\n",
    "                                 vae_latent_z_test,                            \\\n",
    "                                 reuse=False)\n",
    "\n",
    "print ('[info] VAE test model is connected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Total params: 61590385\n",
      "[info] Encoder params: 43808081\n",
      "[info] Decoder params: 17782304\n",
      "\n",
      "[info] trainable variable: \n",
      "['spec_nn_enc/enc_nn_at1/kernel:0', 'spec_nn_enc/enc_nn_at1/bias:0', 'spec_nn_enc/enc_nn_at2/kernel:0', 'spec_nn_enc/enc_nn_at2/bias:0', 'spec_nn_enc/enc_nn_at3/kernel:0', 'spec_nn_enc/enc_nn_at3/bias:0', 'spec_nn_enc/enc_conv1/Conv/weights:0', 'spec_nn_enc/enc_bn1/scale:0', 'spec_nn_enc/enc_bn1/offset:0', 'spec_nn_enc/enc_conv2/Conv/weights:0', 'spec_nn_enc/enc_bn2/scale:0', 'spec_nn_enc/enc_bn2/offset:0', 'spec_nn_enc/enc_conv3/Conv/weights:0', 'spec_nn_enc/enc_bn3/scale:0', 'spec_nn_enc/enc_bn3/offset:0', 'spec_nn_enc/enc_nn_mid_h1/kernel:0', 'spec_nn_enc/enc_nn_mid_h1/bias:0', 'spec_nn_enc/enc_nn_mid_h2/kernel:0', 'spec_nn_enc/enc_nn_mid_h2/bias:0', 'spec_nn_enc/enc_nn_mid_h3/kernel:0', 'spec_nn_enc/enc_nn_mid_h3/bias:0', 'spec_nn_enc/enco_mean/kernel:0', 'spec_nn_enc/enco_mean/bias:0', 'spec_nn_enc/enco_std/kernel:0', 'spec_nn_enc/enco_std/bias:0', 'spec_nn_enc/enc_nnp_h1/kernel:0', 'spec_nn_enc/enc_nnp_h1/bias:0', 'spec_nn_enc/enc_nnp_h2/kernel:0', 'spec_nn_enc/enc_nnp_h2/bias:0', 'spec_nn_enc/enco_nnp_out/kernel:0', 'spec_nn_enc/enco_nnp_out/bias:0', 'spec_nn_dec/dec_nn_at1/kernel:0', 'spec_nn_dec/dec_nn_at1/bias:0', 'spec_nn_dec/dec_nn_at2/kernel:0', 'spec_nn_dec/dec_nn_at2/bias:0', 'spec_nn_dec/dec_nn_at3/kernel:0', 'spec_nn_dec/dec_nn_at3/bias:0', 'spec_nn_dec/dec_nn_at4/kernel:0', 'spec_nn_dec/dec_nn_at4/bias:0', 'spec_nn_dec/dec_nn_at5/kernel:0', 'spec_nn_dec/dec_nn_at5/bias:0', 'spec_nn_dec/dec_nn_mid_h1/kernel:0', 'spec_nn_dec/dec_nn_mid_h1/bias:0', 'spec_nn_dec/dec_nn_mid_h2/kernel:0', 'spec_nn_dec/dec_nn_mid_h2/bias:0', 'spec_nn_dec/dec_nn_mid_h3/kernel:0', 'spec_nn_dec/dec_nn_mid_h3/bias:0', 'spec_nn_dec/dec_nn_mid_h4/kernel:0', 'spec_nn_dec/dec_nn_mid_h4/bias:0', 'spec_nn_dec/dec_nn_mid_h5/kernel:0', 'spec_nn_dec/dec_nn_mid_h5/bias:0', 'spec_nn_dec/dec_nn_mid_h6/kernel:0', 'spec_nn_dec/dec_nn_mid_h6/bias:0', 'spec_nn_dec/dec_nn_out_final/kernel:0', 'spec_nn_dec/dec_nn_out_final/bias:0']\n"
     ]
    }
   ],
   "source": [
    "# Define all trainable variable\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "# count model trainable variables\n",
    "print('[info] Total params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars]).value))\n",
    "print('[info] Encoder params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars if 'spec_nn_enc' in v.name]).value))\n",
    "print('[info] Decoder params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars if 'spec_nn_dec' in v.name]).value))\n",
    "\n",
    "# collect all tf variables\n",
    "nn_model_vars = [var for var in t_vars if 'spec_nn_enc' in var.name]\n",
    "nn_model_vars.extend([var for var in t_vars if 'spec_nn_dec' in var.name])\n",
    "\n",
    "print('\\n[info] trainable variable: ')\n",
    "print([var.name for var in nn_model_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run testing loops here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Testing cell running...\n",
      "[info] 2019-10-19 13:56:51\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./drum_generator_model/darr_model.ckpt\n",
      "[info] Model parameters loaded.\n",
      "\n",
      "\n",
      "[info] Add note complexity: 0\n",
      "[info] Test start...\n",
      "\n",
      "[info] Batch done: [   1 /  37 ],  Note score: 96.59 %\n",
      "[info] Batch done: [   2 /  37 ],  Note score: 97.65 %\n",
      "[info] Batch done: [   3 /  37 ],  Note score: 96.35 %\n",
      "[info] Batch done: [   4 /  37 ],  Note score: 97.64 %\n",
      "[info] Batch done: [   5 /  37 ],  Note score: 97.79 %\n",
      "[info] Batch done: [   6 /  37 ],  Note score: 97.69 %\n",
      "[info] Batch done: [   7 /  37 ],  Note score: 96.41 %\n",
      "[info] Batch done: [   8 /  37 ],  Note score: 97.37 %\n",
      "[info] Batch done: [   9 /  37 ],  Note score: 97.17 %\n",
      "[info] Batch done: [  10 /  37 ],  Note score: 97.25 %\n",
      "[info] Batch done: [  11 /  37 ],  Note score: 97.25 %\n",
      "[info] Batch done: [  12 /  37 ],  Note score: 96.59 %\n",
      "[info] Batch done: [  13 /  37 ],  Note score: 96.59 %\n",
      "[info] Batch done: [  14 /  37 ],  Note score: 98.45 %\n",
      "[info] Batch done: [  15 /  37 ],  Note score: 97.37 %\n",
      "[info] Batch done: [  16 /  37 ],  Note score: 94.96 %\n",
      "[info] Batch done: [  17 /  37 ],  Note score: 97.23 %\n",
      "[info] Batch done: [  18 /  37 ],  Note score: 98.01 %\n",
      "[info] Batch done: [  19 /  37 ],  Note score: 98.28 %\n",
      "[info] Batch done: [  20 /  37 ],  Note score: 97.37 %\n",
      "[info] Batch done: [  21 /  37 ],  Note score: 97.14 %\n",
      "[info] Batch done: [  22 /  37 ],  Note score: 97.36 %\n",
      "[info] Batch done: [  23 /  37 ],  Note score: 97.44 %\n",
      "[info] Batch done: [  24 /  37 ],  Note score: 97.31 %\n",
      "[info] Batch done: [  25 /  37 ],  Note score: 98.18 %\n",
      "[info] Batch done: [  26 /  37 ],  Note score: 98.05 %\n",
      "[info] Batch done: [  27 /  37 ],  Note score: 97.09 %\n",
      "[info] Batch done: [  28 /  37 ],  Note score: 97.12 %\n",
      "[info] Batch done: [  29 /  37 ],  Note score: 97.71 %\n",
      "[info] Batch done: [  30 /  37 ],  Note score: 97.59 %\n",
      "[info] Batch done: [  31 /  37 ],  Note score: 97.62 %\n",
      "[info] Batch done: [  32 /  37 ],  Note score: 97.21 %\n",
      "[info] Batch done: [  33 /  37 ],  Note score: 97.41 %\n",
      "[info] Batch done: [  34 /  37 ],  Note score: 97.55 %\n",
      "[info] Batch done: [  35 /  37 ],  Note score: 98.58 %\n",
      "[info] Batch done: [  36 /  37 ],  Note score: 98.10 %\n",
      "[info] Batch done: [  37 /  37 ],  Note score: 96.76 %\n",
      "\n",
      "[info] Test note score(Avg.): 97.36 %\n",
      "[info] test error notes per bar(736 notes): 19.44\n",
      "[info] Elapse Time: 0:02:02\n",
      "[info] CQT data shape: (2311, 84, 96)\n",
      "[info] Drum data shape (Original): (2311, 46, 16)\n",
      "[info] Drum data shape (predicted): (2311, 46, 16)\n",
      "[info] Saved file:  \"./model_out_result_add_note_00.pkl\"\n",
      "[info] Test session is finished.\n",
      "\n",
      "\n",
      "[info] Add note complexity: 3\n",
      "[info] Test start...\n",
      "\n",
      "[info] Batch done: [   1 /  37 ],  Note score: 96.47 %\n",
      "[info] Batch done: [   2 /  37 ],  Note score: 97.53 %\n",
      "[info] Batch done: [   3 /  37 ],  Note score: 96.21 %\n",
      "[info] Batch done: [   4 /  37 ],  Note score: 97.40 %\n",
      "[info] Batch done: [   5 /  37 ],  Note score: 97.62 %\n",
      "[info] Batch done: [   6 /  37 ],  Note score: 97.46 %\n",
      "[info] Batch done: [   7 /  37 ],  Note score: 96.27 %\n",
      "[info] Batch done: [   8 /  37 ],  Note score: 97.26 %\n",
      "[info] Batch done: [   9 /  37 ],  Note score: 96.86 %\n",
      "[info] Batch done: [  10 /  37 ],  Note score: 97.12 %\n",
      "[info] Batch done: [  11 /  37 ],  Note score: 97.10 %\n",
      "[info] Batch done: [  12 /  37 ],  Note score: 96.45 %\n",
      "[info] Batch done: [  13 /  37 ],  Note score: 96.42 %\n",
      "[info] Batch done: [  14 /  37 ],  Note score: 98.47 %\n",
      "[info] Batch done: [  15 /  37 ],  Note score: 97.34 %\n",
      "[info] Batch done: [  16 /  37 ],  Note score: 94.95 %\n",
      "[info] Batch done: [  17 /  37 ],  Note score: 97.10 %\n",
      "[info] Batch done: [  18 /  37 ],  Note score: 97.88 %\n",
      "[info] Batch done: [  19 /  37 ],  Note score: 98.19 %\n",
      "[info] Batch done: [  20 /  37 ],  Note score: 97.23 %\n",
      "[info] Batch done: [  21 /  37 ],  Note score: 97.01 %\n",
      "[info] Batch done: [  22 /  37 ],  Note score: 97.39 %\n",
      "[info] Batch done: [  23 /  37 ],  Note score: 97.34 %\n",
      "[info] Batch done: [  24 /  37 ],  Note score: 97.11 %\n",
      "[info] Batch done: [  25 /  37 ],  Note score: 98.10 %\n",
      "[info] Batch done: [  26 /  37 ],  Note score: 97.96 %\n",
      "[info] Batch done: [  27 /  37 ],  Note score: 97.01 %\n",
      "[info] Batch done: [  28 /  37 ],  Note score: 96.95 %\n",
      "[info] Batch done: [  29 /  37 ],  Note score: 97.71 %\n",
      "[info] Batch done: [  30 /  37 ],  Note score: 97.45 %\n",
      "[info] Batch done: [  31 /  37 ],  Note score: 97.48 %\n",
      "[info] Batch done: [  32 /  37 ],  Note score: 96.97 %\n",
      "[info] Batch done: [  33 /  37 ],  Note score: 97.39 %\n",
      "[info] Batch done: [  34 /  37 ],  Note score: 97.62 %\n",
      "[info] Batch done: [  35 /  37 ],  Note score: 98.48 %\n",
      "[info] Batch done: [  36 /  37 ],  Note score: 98.06 %\n",
      "[info] Batch done: [  37 /  37 ],  Note score: 96.62 %\n",
      "\n",
      "[info] Test note score(Avg.): 97.24 %\n",
      "[info] test error notes per bar(736 notes): 20.29\n",
      "[info] Elapse Time: 0:04:04\n",
      "[info] CQT data shape: (2311, 84, 96)\n",
      "[info] Drum data shape (Original): (2311, 46, 16)\n",
      "[info] Drum data shape (predicted): (2311, 46, 16)\n",
      "[info] Saved file:  \"./model_out_result_add_note_03.pkl\"\n",
      "[info] Test session is finished.\n",
      "\n",
      "\n",
      "[info] Add note complexity: 6\n",
      "[info] Test start...\n",
      "\n",
      "[info] Batch done: [   1 /  37 ],  Note score: 96.32 %\n",
      "[info] Batch done: [   2 /  37 ],  Note score: 97.40 %\n",
      "[info] Batch done: [   3 /  37 ],  Note score: 96.03 %\n",
      "[info] Batch done: [   4 /  37 ],  Note score: 97.26 %\n",
      "[info] Batch done: [   5 /  37 ],  Note score: 97.54 %\n",
      "[info] Batch done: [   6 /  37 ],  Note score: 97.30 %\n",
      "[info] Batch done: [   7 /  37 ],  Note score: 96.17 %\n",
      "[info] Batch done: [   8 /  37 ],  Note score: 97.11 %\n",
      "[info] Batch done: [   9 /  37 ],  Note score: 96.68 %\n",
      "[info] Batch done: [  10 /  37 ],  Note score: 96.94 %\n",
      "[info] Batch done: [  11 /  37 ],  Note score: 96.97 %\n",
      "[info] Batch done: [  12 /  37 ],  Note score: 96.23 %\n",
      "[info] Batch done: [  13 /  37 ],  Note score: 96.26 %\n",
      "[info] Batch done: [  14 /  37 ],  Note score: 98.35 %\n",
      "[info] Batch done: [  15 /  37 ],  Note score: 97.32 %\n",
      "[info] Batch done: [  16 /  37 ],  Note score: 94.92 %\n",
      "[info] Batch done: [  17 /  37 ],  Note score: 97.00 %\n",
      "[info] Batch done: [  18 /  37 ],  Note score: 97.77 %\n",
      "[info] Batch done: [  19 /  37 ],  Note score: 98.08 %\n",
      "[info] Batch done: [  20 /  37 ],  Note score: 97.07 %\n",
      "[info] Batch done: [  21 /  37 ],  Note score: 96.75 %\n",
      "[info] Batch done: [  22 /  37 ],  Note score: 97.31 %\n",
      "[info] Batch done: [  23 /  37 ],  Note score: 97.25 %\n",
      "[info] Batch done: [  24 /  37 ],  Note score: 97.01 %\n",
      "[info] Batch done: [  25 /  37 ],  Note score: 98.03 %\n",
      "[info] Batch done: [  26 /  37 ],  Note score: 97.93 %\n",
      "[info] Batch done: [  27 /  37 ],  Note score: 96.93 %\n",
      "[info] Batch done: [  28 /  37 ],  Note score: 96.80 %\n",
      "[info] Batch done: [  29 /  37 ],  Note score: 97.65 %\n",
      "[info] Batch done: [  30 /  37 ],  Note score: 97.34 %\n",
      "[info] Batch done: [  31 /  37 ],  Note score: 97.41 %\n",
      "[info] Batch done: [  32 /  37 ],  Note score: 96.84 %\n",
      "[info] Batch done: [  33 /  37 ],  Note score: 97.26 %\n",
      "[info] Batch done: [  34 /  37 ],  Note score: 97.53 %\n",
      "[info] Batch done: [  35 /  37 ],  Note score: 98.41 %\n",
      "[info] Batch done: [  36 /  37 ],  Note score: 98.04 %\n",
      "[info] Batch done: [  37 /  37 ],  Note score: 96.58 %\n",
      "\n",
      "[info] Test note score(Avg.): 97.13 %\n",
      "[info] test error notes per bar(736 notes): 21.13\n",
      "[info] Elapse Time: 0:06:06\n",
      "[info] CQT data shape: (2311, 84, 96)\n",
      "[info] Drum data shape (Original): (2311, 46, 16)\n",
      "[info] Drum data shape (predicted): (2311, 46, 16)\n",
      "[info] Saved file:  \"./model_out_result_add_note_06.pkl\"\n",
      "[info] Test session is finished.\n",
      "\n",
      "\n",
      "[info] Add note complexity: 12\n",
      "[info] Test start...\n",
      "\n",
      "[info] Batch done: [   1 /  37 ],  Note score: 95.81 %\n",
      "[info] Batch done: [   2 /  37 ],  Note score: 96.99 %\n",
      "[info] Batch done: [   3 /  37 ],  Note score: 95.61 %\n",
      "[info] Batch done: [   4 /  37 ],  Note score: 97.08 %\n",
      "[info] Batch done: [   5 /  37 ],  Note score: 97.27 %\n",
      "[info] Batch done: [   6 /  37 ],  Note score: 97.10 %\n",
      "[info] Batch done: [   7 /  37 ],  Note score: 95.69 %\n",
      "[info] Batch done: [   8 /  37 ],  Note score: 96.79 %\n",
      "[info] Batch done: [   9 /  37 ],  Note score: 96.57 %\n",
      "[info] Batch done: [  10 /  37 ],  Note score: 96.82 %\n",
      "[info] Batch done: [  11 /  37 ],  Note score: 96.51 %\n",
      "[info] Batch done: [  12 /  37 ],  Note score: 95.79 %\n",
      "[info] Batch done: [  13 /  37 ],  Note score: 95.86 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Batch done: [  14 /  37 ],  Note score: 98.01 %\n",
      "[info] Batch done: [  15 /  37 ],  Note score: 97.14 %\n",
      "[info] Batch done: [  16 /  37 ],  Note score: 94.59 %\n",
      "[info] Batch done: [  17 /  37 ],  Note score: 96.55 %\n",
      "[info] Batch done: [  18 /  37 ],  Note score: 97.49 %\n",
      "[info] Batch done: [  19 /  37 ],  Note score: 97.73 %\n",
      "[info] Batch done: [  20 /  37 ],  Note score: 96.76 %\n",
      "[info] Batch done: [  21 /  37 ],  Note score: 96.25 %\n",
      "[info] Batch done: [  22 /  37 ],  Note score: 96.98 %\n",
      "[info] Batch done: [  23 /  37 ],  Note score: 97.11 %\n",
      "[info] Batch done: [  24 /  37 ],  Note score: 96.80 %\n",
      "[info] Batch done: [  25 /  37 ],  Note score: 97.87 %\n",
      "[info] Batch done: [  26 /  37 ],  Note score: 97.73 %\n",
      "[info] Batch done: [  27 /  37 ],  Note score: 96.70 %\n",
      "[info] Batch done: [  28 /  37 ],  Note score: 96.60 %\n",
      "[info] Batch done: [  29 /  37 ],  Note score: 97.37 %\n",
      "[info] Batch done: [  30 /  37 ],  Note score: 96.98 %\n",
      "[info] Batch done: [  31 /  37 ],  Note score: 97.09 %\n",
      "[info] Batch done: [  32 /  37 ],  Note score: 96.54 %\n",
      "[info] Batch done: [  33 /  37 ],  Note score: 97.21 %\n",
      "[info] Batch done: [  34 /  37 ],  Note score: 97.31 %\n",
      "[info] Batch done: [  35 /  37 ],  Note score: 98.10 %\n",
      "[info] Batch done: [  36 /  37 ],  Note score: 97.84 %\n",
      "[info] Batch done: [  37 /  37 ],  Note score: 96.17 %\n",
      "\n",
      "[info] Test note score(Avg.): 96.83 %\n",
      "[info] test error notes per bar(736 notes): 23.31\n",
      "[info] Elapse Time: 0:08:07\n",
      "[info] CQT data shape: (2311, 84, 96)\n",
      "[info] Drum data shape (Original): (2311, 46, 16)\n",
      "[info] Drum data shape (predicted): (2311, 46, 16)\n",
      "[info] Saved file:  \"./model_out_result_add_note_12.pkl\"\n",
      "[info] Test session is finished.\n",
      "\n",
      "\n",
      "[info] Add note complexity: 20\n",
      "[info] Test start...\n",
      "\n",
      "[info] Batch done: [   1 /  37 ],  Note score: 94.97 %\n",
      "[info] Batch done: [   2 /  37 ],  Note score: 96.39 %\n",
      "[info] Batch done: [   3 /  37 ],  Note score: 95.12 %\n",
      "[info] Batch done: [   4 /  37 ],  Note score: 96.66 %\n",
      "[info] Batch done: [   5 /  37 ],  Note score: 96.84 %\n",
      "[info] Batch done: [   6 /  37 ],  Note score: 96.72 %\n",
      "[info] Batch done: [   7 /  37 ],  Note score: 95.17 %\n",
      "[info] Batch done: [   8 /  37 ],  Note score: 96.20 %\n",
      "[info] Batch done: [   9 /  37 ],  Note score: 96.20 %\n",
      "[info] Batch done: [  10 /  37 ],  Note score: 96.52 %\n",
      "[info] Batch done: [  11 /  37 ],  Note score: 95.94 %\n",
      "[info] Batch done: [  12 /  37 ],  Note score: 95.17 %\n",
      "[info] Batch done: [  13 /  37 ],  Note score: 95.33 %\n",
      "[info] Batch done: [  14 /  37 ],  Note score: 97.52 %\n",
      "[info] Batch done: [  15 /  37 ],  Note score: 96.65 %\n",
      "[info] Batch done: [  16 /  37 ],  Note score: 94.45 %\n",
      "[info] Batch done: [  17 /  37 ],  Note score: 95.56 %\n",
      "[info] Batch done: [  18 /  37 ],  Note score: 97.02 %\n",
      "[info] Batch done: [  19 /  37 ],  Note score: 97.09 %\n",
      "[info] Batch done: [  20 /  37 ],  Note score: 96.30 %\n",
      "[info] Batch done: [  21 /  37 ],  Note score: 95.92 %\n",
      "[info] Batch done: [  22 /  37 ],  Note score: 96.79 %\n",
      "[info] Batch done: [  23 /  37 ],  Note score: 96.53 %\n",
      "[info] Batch done: [  24 /  37 ],  Note score: 96.52 %\n",
      "[info] Batch done: [  25 /  37 ],  Note score: 97.31 %\n",
      "[info] Batch done: [  26 /  37 ],  Note score: 97.37 %\n",
      "[info] Batch done: [  27 /  37 ],  Note score: 96.36 %\n",
      "[info] Batch done: [  28 /  37 ],  Note score: 96.04 %\n",
      "[info] Batch done: [  29 /  37 ],  Note score: 96.94 %\n",
      "[info] Batch done: [  30 /  37 ],  Note score: 96.59 %\n",
      "[info] Batch done: [  31 /  37 ],  Note score: 96.48 %\n",
      "[info] Batch done: [  32 /  37 ],  Note score: 96.11 %\n",
      "[info] Batch done: [  33 /  37 ],  Note score: 96.94 %\n",
      "[info] Batch done: [  34 /  37 ],  Note score: 96.85 %\n",
      "[info] Batch done: [  35 /  37 ],  Note score: 97.62 %\n",
      "[info] Batch done: [  36 /  37 ],  Note score: 97.55 %\n",
      "[info] Batch done: [  37 /  37 ],  Note score: 95.36 %\n",
      "\n",
      "[info] Test note score(Avg.): 96.35 %\n",
      "[info] test error notes per bar(736 notes): 26.84\n",
      "[info] Elapse Time: 0:10:09\n",
      "[info] CQT data shape: (2311, 84, 96)\n",
      "[info] Drum data shape (Original): (2311, 46, 16)\n",
      "[info] Drum data shape (predicted): (2311, 46, 16)\n",
      "[info] Saved file:  \"./model_out_result_add_note_20.pkl\"\n",
      "[info] Test session is finished.\n",
      "\n",
      "\n",
      "[info] All testing process is finished.\n",
      "[info] 2019-10-19 14:07:00\n"
     ]
    }
   ],
   "source": [
    "show_info_epoch = 1; show_info_batch = 1;\n",
    "\n",
    "print (\"[info] Testing cell running...\")\n",
    "print ('[info] ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '\\n')\n",
    "\n",
    "# init tensorflow variables\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=nn_model_vars)\n",
    "darr_model_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "darr_model_config.gpu_options.allow_growth = True\n",
    "\n",
    "# run TF session here\n",
    "with tf.Session(config=darr_model_config) as sess:\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # reload model\n",
    "    saver.restore(sess, './drum_generator_model/darr_model.ckpt')\n",
    "    print ('[info] Model parameters loaded.')\n",
    "    \n",
    "    epoch_target = 1\n",
    "    \n",
    "    # run Epoch loop here\n",
    "    for add_note_v in bar_add_note_num_list:\n",
    "\n",
    "        print ('\\n')\n",
    "        print ('[info] Add note complexity: {}'.format(add_note_v))\n",
    "        print ('[info] Test start...\\n')\n",
    "        \n",
    "        sess.run(test_iter.initializer)\n",
    "\n",
    "        note_score_test_list = []\n",
    "\n",
    "        session_bar_cqt_data_test_list = []\n",
    "        session_bar_note_num_test_list = []\n",
    "        session_bar_note_num_pred_test_list = []\n",
    "        session_bar_arrange_test_list = []\n",
    "        session_darr_output_test_list = []\n",
    "        \n",
    "        batch_target_test = np.int(len(abs_bar_idx_str_list_ext)/batch_size)        \n",
    "        batch_runned_test = 0 \n",
    "        \n",
    "        # run batch loop here\n",
    "        for batch_idx in range(0, batch_target_test):            \n",
    "            \n",
    "            # run model testing            \n",
    "            session_bar_cqt_data_test,             \\\n",
    "            session_bar_style_data_test,           \\\n",
    "            session_bar_tempo_data_test,           \\\n",
    "            session_bar_note_num_test,             \\\n",
    "            session_bar_progress_test,             \\\n",
    "            session_bar_arrange_test,              \\\n",
    "            session_bar_note_num_pred_test,        \\\n",
    "            session_darr_output_test = sess.run([batch_bar_cqt_data_test,  \\\n",
    "                                       batch_bar_style_data_test,          \\\n",
    "                                       batch_bar_tempo_data_test,          \\\n",
    "                                       batch_bar_note_num_test,            \\\n",
    "                                       batch_bar_progress_test,            \\\n",
    "                                       batch_bar_arrange_test,             \\\n",
    "                                       vae_note_pred_test,                 \\\n",
    "                                       vae_drum_out_test],                 \\\n",
    "                                      feed_dict={tfph_bar_add_note_num: np.array([add_note_v])})\n",
    "            \n",
    "            # get correct shape of data\n",
    "            session_bar_cqt_data_test = session_bar_cqt_data_test.copy()[:,:,:,0]\n",
    "            session_bar_arrange_test = session_bar_arrange_test.copy()[:,:,:,0]\n",
    "            session_darr_output_test = session_darr_output_test.copy()[:,:,:,0]\n",
    "            \n",
    "            # calculate note score\n",
    "            session_darr_output_test_bin = np.where(session_darr_output_test>=0.5,\n",
    "                                                    np.ones_like(session_darr_output_test),\n",
    "                                                    np.zeros_like(session_darr_output_test))  \n",
    "\n",
    "            note_score_test = 1.0 - np.sum(np.abs(                        \\\n",
    "                session_bar_arrange_test - session_darr_output_test_bin))/np.prod(session_bar_arrange_test.shape)\n",
    "            \n",
    "            note_score_test_list.append(note_score_test)\n",
    "            \n",
    "            # record every batch data\n",
    "            session_bar_cqt_data_test_list.append(session_bar_cqt_data_test)\n",
    "            session_bar_note_num_test_list.append(session_bar_note_num_test)\n",
    "            session_bar_note_num_pred_test_list.append(session_bar_note_num_pred_test)\n",
    "            session_bar_arrange_test_list.append(session_bar_arrange_test)\n",
    "            session_darr_output_test_list.append(session_darr_output_test)\n",
    "                \n",
    "            # record runned batch\n",
    "            batch_runned_test += 1\n",
    "            \n",
    "            if (batch_runned_test%show_info_batch)==0:\n",
    "                out_msg = \"[info] Batch done: [ {:3d} / {:3d} ]\".format(batch_runned_test, batch_target_test)\n",
    "                out_msg += \",  Note score: {:.2f} %\".format(100*np.mean(note_score_test_list[-show_info_batch:]))\n",
    "                print (out_msg)             \n",
    "            \n",
    "        delta_time = datetime.datetime.now() - start_time\n",
    "        \n",
    "        out_msg  = \"\\n[info] Test note score(Avg.): {:.2f} %\".format(100*np.mean(note_score_test_list))\n",
    "        out_msg += \"\\n[info] test error notes per bar({} notes): {:.2f}\".format(dec_output_size, \n",
    "                                                                                (1-np.mean(note_score_test_list))*dec_output_size)\n",
    "        out_msg += \"\\n[info] Elapse Time: {}\".format(str(delta_time)[:-7])        \n",
    "        print (out_msg)\n",
    "        \n",
    "        # save calculation result\n",
    "        cqt_data_ary   = np.concatenate(session_bar_cqt_data_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n",
    "        drum_original  = np.concatenate(session_bar_arrange_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n",
    "        drum_predicted = np.concatenate(session_darr_output_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n",
    "        dump_data_pkg = [cqt_data_ary, drum_original, drum_predicted]\n",
    "\n",
    "        print(\"[info] CQT data shape: {}\".format(cqt_data_ary.shape))\n",
    "        print(\"[info] Drum data shape (Original): {}\".format(drum_original.shape))\n",
    "        print(\"[info] Drum data shape (predicted): {}\".format(drum_predicted.shape))\n",
    "\n",
    "        dump_file_name = './model_out_result_add_note_{:0>2}.pkl'.format(add_note_v)\n",
    "        with open(dump_file_name, 'wb') as pkl_file:\n",
    "            pickle.dump(dump_data_pkg, pkl_file)\n",
    "\n",
    "        print ('[info] Saved file:  \\\"{}\\\"'.format(dump_file_name))\n",
    "        \n",
    "        # test data session end            \n",
    "        print ('[info] Test session is finished.')   \n",
    "    \n",
    "# show process is end\n",
    "print (\"\\n\\n[info] All testing process is finished.\")\n",
    "print (\"[info] \" + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensure DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save s100 p00n/p03n/p06n/p12n/p20n test result here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] s100 v033, 0p8, p03n test result saved.\n",
      "[info] saved file:  \"./model_test_result_bm24_vaegan/v033/rc_loss_0p8/bm24_p03n_result_pkg.pkl\"\n"
     ]
    }
   ],
   "source": [
    "test_result_train_pp = [session_bar_cqt_data_train_list,\n",
    "                        session_bar_note_num_train_list,\n",
    "                        session_bar_note_num_pred_train_list,\n",
    "                        session_bar_arrange_train_list,\n",
    "                        session_darr_output_train_list]\n",
    "\n",
    "\n",
    "test_s100_result_fname = './model_test_result_bm24_vaegan/{}/rc_loss_{}/'.format(chkpt_ver, rc_loss_ver)\n",
    "test_s100_result_fname += 'bm24_{}_result_pkg.pkl'.format(add_note_ver)\n",
    "\n",
    "ensure_dir(test_s100_result_fname)\n",
    "with open(test_s100_result_fname, 'wb') as pkl_file:\n",
    "    pickle.dump(test_result_train_pp, pkl_file)\n",
    "    \n",
    "print ('[info] s100 {}, {}, {} test result saved.'.format(chkpt_ver, rc_loss_ver, add_note_ver))\n",
    "print ('[info] saved file:  \\\"{}\\\"'.format(test_s100_result_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
